{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e894955a-e101-47db-bde1-1e08ea104a85",
   "metadata": {},
   "source": [
    "# Cellpose program. \n",
    "\n",
    "This is a program used to generate a new cellpose model based on a series of representative images and their corresponding labelled images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93c16d4-d2d7-4b6a-9679-d35d00fce944",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from cellpose import core, models, io, metrics\n",
    "\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import tqdm \n",
    "import tifffile as tf\n",
    "\n",
    "import tqdm\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f03d8ba-8085-465f-8d46-c1243919bca8",
   "metadata": {},
   "source": [
    "-------\n",
    "### Write in cell type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad2589c-847d-46a2-bd91-e4a2422c26aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cell_type = '_Abhi_cells_circs'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09eb4444-cdc3-4c47-9e4e-97f3e4b77705",
   "metadata": {},
   "source": [
    "### set the Folder path for the test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2833fce-fdf8-433d-8cf6-bae62e3668d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "root = tk.Tk()\n",
    "root.withdraw() # Stops a second window opening\n",
    "image_folder = filedialog.askdirectory(title = 'Select image Folder')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c6a8282-c862-4922-babd-bc6483ff3236",
   "metadata": {},
   "source": [
    "### Set the folder path for the user defined masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70550f82-8c6d-4722-bee4-a313c99a8b8d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "root = tk.Tk()\n",
    "root.withdraw() # Stops a second window opening\n",
    "mask_folder = filedialog.askdirectory(title = 'Select Masks Folder')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7205c4b4-a1da-4e34-bd9a-765dbacadc70",
   "metadata": {},
   "source": [
    "--------------\n",
    "## Create a method to extract all the filenames from a folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99500acf-d7d8-4ce1-b18a-53d0b613084e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_files_from_folder(folder_path): \n",
    "    '''A method to extract all files from the image.'''\n",
    "\n",
    "    file_list = os.listdir(folder_path)\n",
    "    image_files = []\n",
    "    \n",
    "    for i in range( len(file_list) ): \n",
    "        if file_list[i][-4:] == '.tif' or file_list[i][-4:] == '.png':\n",
    "            image_files.append(file_list[i])\n",
    "        \n",
    "    return(image_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f19685-48ef-4a0f-ac5b-bac029ae70f7",
   "metadata": {},
   "source": [
    "----\n",
    "## Create a method to download in the image data from the image file name. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34bdb4c1-abd0-4a8b-a57e-2a0af7370722",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_image_data(image_file):\n",
    "    '''Get the image data from the file using Pillow.\n",
    "    Convert the PILLOW image to a numpy array'''\n",
    "\n",
    "    image_data = tf.imread(image_file)\n",
    "    \n",
    "    # print(image_data.getexif())\n",
    "    \n",
    "    np_image_data = np.array(image_data)\n",
    "\n",
    "    return(np_image_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaaab65a-34cf-43d1-baa4-ae40f3f0703d",
   "metadata": {},
   "source": [
    "-----\n",
    "## Collect the image files from folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1237af7-06f0-42ff-ac68-4c00184b31fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_file_list = get_files_from_folder(image_folder)\n",
    "mask_file_list = get_files_from_folder(mask_folder)\n",
    "\n",
    "\n",
    "print(image_folder)\n",
    "print(mask_folder)\n",
    "print( len(image_file_list) )\n",
    "print( len(mask_file_list) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b1ff93e-bd8f-44e2-a5ee-0a9e6a5c7a70",
   "metadata": {
    "tags": []
   },
   "source": [
    "----\n",
    "## extract datasets for testing/training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819862a3-0f01-43ad-a51c-5583c83a2a38",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_image_index = np.random.choice(len(image_file_list)-1, size = int(0.8*(len(image_file_list)-1)), replace = False)\n",
    "\n",
    "print('Training image Files :' + str(np.sort(training_image_index)) )\n",
    "print('Number of training Images: ' + str(len(training_image_index)))\n",
    "\n",
    "# Create test image index. \n",
    "test_image_index = []\n",
    "\n",
    "for i in range(len(image_file_list)):\n",
    "    if len(np.where(training_image_index == i)[0]) == 0:\n",
    "        test_image_index.append(i)\n",
    "\n",
    "print('Validation image files :' + str(test_image_index) )\n",
    "print('Number of Validation Images: ' + str(len(test_image_index)) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05aee83-72d4-4b01-a53d-400332bf3c65",
   "metadata": {},
   "source": [
    "--------\n",
    "## Get test images and user_masks into a format for cellpose model Training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a267643-9643-4c1c-9e0d-c691cc59895e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialise \n",
    "ground_truth_training = []\n",
    "training_images = []\n",
    "\n",
    "for i in range(len(training_image_index)):\n",
    "    # get the image data\n",
    "    image_file_name = image_file_list[training_image_index[i]]\n",
    "    individual_image = get_image_data(image_folder + '/'+ image_file_name)\n",
    "    training_images.append(individual_image)\n",
    "    # get the corresponding user_defined_mask\n",
    "    mask_file_name = image_file_name[0:-4] + '.tif'\n",
    "    # print(image_file_name)\n",
    "    # print(mask_file_name)\n",
    "    user_mask = get_image_data(mask_folder + '/'+ mask_file_name)\n",
    "    ground_truth_training.append(user_mask)\n",
    "\n",
    "    \n",
    "# ground_truth = np.array(ground_truth)\n",
    "print(training_images[0].shape)\n",
    "print(ground_truth_training[0].shape)\n",
    "print(len(training_images))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cfed344-8d9a-4e10-a5f9-0908a7373e06",
   "metadata": {},
   "source": [
    "-----\n",
    "## Get test images and user_masks into a format for cellpose model evaluation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356245ad-eb05-456a-83f7-5611ac05c521",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ground_truth_test = []\n",
    "test_images = []\n",
    "\n",
    "for i in range(len(test_image_index)):\n",
    "    # get the image data\n",
    "    image_file_name = image_file_list[test_image_index[i]]\n",
    "    individual_image = get_image_data(image_folder + '/'+ image_file_name)\n",
    "    test_images.append(individual_image)\n",
    "    # get the corresponding user_defined_mask\n",
    "    mask_file_name = image_file_name[0:-4] + '.tif'\n",
    "    # print(image_file_name)\n",
    "    # print(mask_file_name)\n",
    "    user_mask = get_image_data(mask_folder + '/'+ mask_file_name)\n",
    "    ground_truth_test.append(user_mask)\n",
    "\n",
    "    \n",
    "# ground_truth = np.array(ground_truth)\n",
    "print(test_images[i].shape)\n",
    "print(ground_truth_test[i].shape)\n",
    "print(len(test_images))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe4de43-299d-4ae3-81af-6fbc31aebf89",
   "metadata": {},
   "source": [
    "---------\n",
    "### Create a meta_data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6baef150-9250-4b12-9df7-7de945a06952",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_metadata():\n",
    "    '''Save the training parameters for the deep learning model.  '''\n",
    "\n",
    "    meta_data = pd.DataFrame({'model_name': [model_name], \n",
    "                              'Number of Training Images': [num_training_ims], \n",
    "                              'Number of Test Images': [num_testing_ims], \n",
    "                              'Number of Epochs': [n_epochs],  \n",
    "                              'Learning Rate for training': [learning_rate], \n",
    "                              'Weight Decay for training': [weight_decay], \n",
    "                              'Training data split': [training_data_split], \n",
    "                              'Validation data split': [1 - training_data_split], \n",
    "                              'Number of images per epoch': [ims_per_epoch], \n",
    "                              'Model from the zoo': [start_model], \n",
    "                              'Model Accuracy': [ap[:,0].mean()]})\n",
    "    \n",
    "    meta_data.to_csv(\n",
    "                    os.path.dirname(image_folder) + '/models/' + model_name + '_meatadata.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657ca6b2-5ca1-4192-8f59-8a0ba40d6c5c",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "---\n",
    "## I will attempt to train a model on the training datasets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b19b2d0-43fa-47ca-bbbc-a649493df1e6",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This cell is taken directly from the Colab notebook and then \n",
    "# modified for my needs. \n",
    "\n",
    "# Get the time and date for the mask name. \n",
    "date_time_vals = str(datetime.datetime.now())\n",
    "\n",
    "date = date_time_vals[0:10].replace('-', '_')\n",
    "\n",
    "point_find = date_time_vals.find('.')\n",
    "time = date_time_vals[11:point_find].replace(':', '_')\n",
    "\n",
    "start_model = 'cyto'\n",
    "\n",
    "# start logger (to see training across epochs)\n",
    "logger = io.logger_setup()\n",
    "\n",
    "# set channels\n",
    "channels = [0, 0]\n",
    "\n",
    "n_epochs = 100\n",
    "\n",
    "learning_rate = 0.1\n",
    "\n",
    "weight_decay = 0.0001\n",
    "\n",
    "ims_per_epoch = 8\n",
    "\n",
    "training_data_split = 0.8\n",
    "\n",
    "num_training_ims = int(training_data_split * len(training_images)) \n",
    "\n",
    "num_testing_ims = len(training_images) - int(training_data_split * len(training_images)) \n",
    "\n",
    "model_name =  date + '_' + time + '_' + cell_type \n",
    "\n",
    "# DEFINE CELLPOSE MODEL (without size model)\n",
    "model = models.CellposeModel(gpu=True, model_type=start_model)\n",
    "# model = openvino_utils.to_openvino(model)\n",
    "\n",
    "test_files2 = list(test_images)\n",
    "test_masks2 = list(ground_truth_test)\n",
    "\n",
    "new_model_path = model.train(training_images[0 : num_training_ims ], ground_truth_training[0 : num_training_ims ], \n",
    "                              test_data=training_images[num_training_ims:],\n",
    "                              test_labels=ground_truth_training[num_training_ims:],\n",
    "                              channels=channels, \n",
    "                              save_path=os.path.dirname(image_folder), \n",
    "                              n_epochs=n_epochs,\n",
    "                              learning_rate=learning_rate, \n",
    "                              weight_decay=weight_decay, \n",
    "                              nimg_per_epoch=ims_per_epoch,\n",
    "                              model_name = model_name )\n",
    "\n",
    "# diameter of labels in training images\n",
    "diam_labels = model.diam_labels.copy()\n",
    "\n",
    "print(test_images[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef0769d-dd45-4530-af46-0c48c8db4d3a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "retrained_masks = []\n",
    "\n",
    "model_path = 'C:/Users/rcorbyn/.cellpose/models/' + '2024_06_05_14_36_50__Abhi_cells_circs'\n",
    "model_name = '2024_06_05_14_36_50__Abhi_cells_circs'\n",
    "print(model_path)\n",
    "\n",
    "# declare model\n",
    "model = models.CellposeModel(gpu=True, pretrained_model=model_path)\n",
    "\n",
    "for i in tqdm.tqdm(range(len(test_images) )):\n",
    "    masks = model.eval(test_images[i], channels = [0, 0], diameter = None)[0]\n",
    "    retrained_masks.append(masks)\n",
    "\n",
    "# Check the performance of the model using IoU metric. \n",
    "ap = metrics.average_precision(ground_truth_test, retrained_masks)[0]\n",
    "print(ap[:,0].mean()) \n",
    "\n",
    "save_metadata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac873ce-5bb4-4832-931c-643b2cc42b82",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in range( len(test_image_index) ):\n",
    "    print(image_file_list[test_image_index[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771f7969-9ee5-4d86-a14f-8ad3ab50381b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "im = 10\n",
    "fig1, ax1 = plt.subplots()\n",
    "ax1.imshow(test_images[im][ :, :], vmin = 50)\n",
    "ax1.imshow(retrained_masks[im], alpha = 0.25, cmap = 'inferno_r', vmax = 1)\n",
    "ax1.set_title('Cellpose Masks')\n",
    "\n",
    "fig3, ax3 = plt.subplots()\n",
    "ax3.imshow(test_images[im][ :, :], vmin = 50)\n",
    "ax3.imshow(ground_truth_test[im], alpha = 0.25, cmap = 'inferno_r', vmax = 1)\n",
    "ax3.set_title('Ground truth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc6822c-2776-436d-ba64-f3682f7535c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(test_images[im].shape)\n",
    "print(len(retrained_masks))\n",
    "# %matplotlib\n",
    "# plt.figure(figsize=(40,16))\n",
    "fig, ax = plt.subplots()\n",
    "ax.imshow(test_images[im][ :, :])\n",
    "fig2, ax2 = plt.subplots()\n",
    "ax2.imshow(retrained_masks[im], alpha = 0.25, cmap = 'inferno_r', vmax = 1)\n",
    "# print(np.max(retrained_masks[2]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55aca00-d6a1-48cb-a94a-6683de4c6088",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45855b96-3ac5-400b-8b65-ca949f52403d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01cf911-c7c8-442c-9e1c-e470fc4b59aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
